Tips
=====

How to add tags based on filed content with pipelines?
--------------------------------------------------------

If the filed's name is known, it can be used directly. If not, use "message" which holds everything.

::

  filter {
    if [message] =~ /regexp/ {
      mutate {
        add_tag => [ "tag1", "tag2" ]
      }
    }
  }

Add Tags to Different Kafka Topics
------------------------------------

**Notes:** [@metadata][kafka][topic] will be empty sometimes due to unknown issues. Hence this tip is listed here for reference.

::

  input {
    kafka {
      client_id => "logstash_server"
      group_id => "logstash"
      topics => ["unity", "xio"]
      codec => "json"
      bootstrap_servers => "kafka_server1:9092,kafka_server2:9092,kafka_server3:9092"
    }
  }

  filter {
    if [@metadata][kafka][topic] == "unity" {
      mutate { add_tag => ["unity"] }
    }
    if [@metadata][kafka][topic] == "xio" {
      mutate { add_tag => ["xio"] }
    }
  }

  output {
    elasticsearch {
      hosts => ["http://elasticsearch1:9200", "http://elasticsearch2:9200", "http://elasticsearch3:9200"]
      index => "storagebox-%{+YYYY.MM.dd}"
    }
  }

Rename the Host Field while Sending Filebeat Events to Logstash
-----------------------------------------------------------------

If filebeat is sending events to Elasticsearch directly, everything works fine. However, if filebeat is sending events to an index already used by Logstash where syslog(TCP/UDP input) is also sending events to, error on the host filed will be raised:

- TCP/UDP input plugin of Logstash will add a field **host** to stand for where the information is generated. This field is a string;
- Filebeat sends events with a filed **host** which is an object(dict);
- Because of the difference, Elasticsearch cannot map the host field correctly and generate index accordingly.

To fix this, the mutate filter plugin can be used to rename the host field of Filebeat to a new name as below:

::

  filter {
    mutate {
      rename => ["host", "server"]
    }
  }

Consolidate Unix Logs with NXLog
---------------------------------

System logs can be consolidated to Elasticsearch directly on Unix systems (AIX, Solaris, FreeBSE, HP-UX) by configuring syslog forwarding, however, there is no way to forward non-system logs, such as logs generated by applications, due to the fact that Filebeat only supports Linux and Windows.

NXLog can be leveraged on Unix systems to consolidate such logs. Please refer to `NXLog User Guide <https://nxlog.co/documentation/nxlog-user-guide/>`_ for reference.
